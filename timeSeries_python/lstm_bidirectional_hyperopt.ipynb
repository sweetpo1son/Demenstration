{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-self-attention\r\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from keras-self-attention) (1.17.0)\r\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.6/site-packages (from keras-self-attention) (2.2.4)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-self-attention) (1.12.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-self-attention) (1.2.1)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-self-attention) (1.1.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras->keras-self-attention) (5.1.2)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-self-attention) (1.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras->keras-self-attention) (2.9.0)\r\n",
      "Building wheels for collected packages: keras-self-attention\r\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17289 sha256=968fc144e3d8dd53a31b18438af315edea6dabede07c700ff80aa47f995c6fff\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\r\n",
      "Successfully built keras-self-attention\r\n",
      "Installing collected packages: keras-self-attention\r\n",
      "Successfully installed keras-self-attention-0.41.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6574\n",
      "6575\n",
      "Epoch 1/30\n",
      " - 53s - loss: 41.8254\n",
      "\n",
      "Epoch 2/30\n",
      " - 44s - loss: 3.0110\n",
      "\n",
      "Epoch 3/30\n",
      " - 44s - loss: 2.6332\n",
      "\n",
      "Epoch 4/30\n",
      " - 44s - loss: 2.3101\n",
      "\n",
      "Epoch 5/30\n",
      " - 44s - loss: 2.0306\n",
      "\n",
      "Epoch 6/30\n",
      " - 44s - loss: 1.7900\n",
      "\n",
      "Epoch 7/30\n",
      " - 43s - loss: 1.5939\n",
      "\n",
      "Epoch 8/30\n",
      " - 44s - loss: 1.4308\n",
      "\n",
      "Epoch 9/30\n",
      " - 43s - loss: 1.2920\n",
      "\n",
      "Epoch 10/30\n",
      " - 44s - loss: 1.1797\n",
      "\n",
      "Epoch 11/30\n",
      " - 44s - loss: 1.1133\n",
      "\n",
      "Epoch 12/30\n",
      " - 44s - loss: 1.1172\n",
      "\n",
      "Epoch 13/30\n",
      " - 43s - loss: 1.1259\n",
      "\n",
      "Epoch 14/30\n",
      " - 43s - loss: 1.1301\n",
      "\n",
      "Epoch 15/30\n",
      " - 43s - loss: 1.1313\n",
      "\n",
      "Epoch 16/30\n",
      " - 43s - loss: 1.1322\n",
      "\n",
      "Epoch 17/30\n",
      " - 44s - loss: 1.1336\n",
      "\n",
      "Epoch 18/30\n",
      " - 43s - loss: 1.1356\n",
      "\n",
      "Epoch 19/30\n",
      " - 44s - loss: 1.1373\n",
      "\n",
      "Epoch 20/30\n",
      " - 43s - loss: 1.1377\n",
      "\n",
      "Epoch 21/30\n",
      " - 43s - loss: 1.1374\n",
      "\n",
      "Epoch 22/30\n",
      " - 43s - loss: 1.1370\n",
      "\n",
      "Epoch 23/30\n",
      " - 43s - loss: 1.1367\n",
      "\n",
      "Epoch 24/30\n",
      " - 43s - loss: 1.1366\n",
      "\n",
      "Epoch 25/30\n",
      " - 43s - loss: 1.1369\n",
      "\n",
      "Epoch 26/30\n",
      " - 44s - loss: 1.1368\n",
      "\n",
      "Epoch 27/30\n",
      " - 43s - loss: 1.1368\n",
      "\n",
      "Epoch 28/30\n",
      " - 43s - loss: 1.1370\n",
      "\n",
      "Epoch 29/30\n",
      " - 43s - loss: 1.1372\n",
      "\n",
      "Epoch 30/30\n",
      " - 43s - loss: 1.1373\n",
      "\n",
      "Epoch 1/30\n",
      " - 23s - loss: 68.2677\n",
      "\n",
      "Epoch 2/30\n",
      " - 18s - loss: 5.1065\n",
      "\n",
      "Epoch 3/30\n",
      " - 18s - loss: 2.4044\n",
      "\n",
      "Epoch 4/30\n",
      " - 18s - loss: 2.2127\n",
      "\n",
      "Epoch 5/30\n",
      " - 18s - loss: 2.0813\n",
      "\n",
      "Epoch 6/30\n",
      " - 18s - loss: 1.9588\n",
      "\n",
      "Epoch 7/30\n",
      " - 18s - loss: 1.8412\n",
      "\n",
      "Epoch 8/30\n",
      " - 18s - loss: 1.7302\n",
      "\n",
      "Epoch 9/30\n",
      " - 18s - loss: 1.6254\n",
      "\n",
      "Epoch 10/30\n",
      " - 18s - loss: 1.5267\n",
      "\n",
      "Epoch 11/30\n",
      " - 18s - loss: 1.4326\n",
      "\n",
      "Epoch 12/30\n",
      " - 18s - loss: 1.3456\n",
      "\n",
      "Epoch 13/30\n",
      " - 18s - loss: 1.2632\n",
      "\n",
      "Epoch 14/30\n",
      " - 18s - loss: 1.1866\n",
      "\n",
      "Epoch 15/30\n",
      " - 18s - loss: 1.1141\n",
      "\n",
      "Epoch 16/30\n",
      " - 18s - loss: 1.0462\n",
      "\n",
      "Epoch 17/30\n",
      " - 18s - loss: 0.9828\n",
      "\n",
      "Epoch 18/30\n",
      " - 18s - loss: 0.9245\n",
      "\n",
      "Epoch 19/30\n",
      " - 18s - loss: 0.8700\n",
      "\n",
      "Epoch 20/30\n",
      " - 18s - loss: 0.8197\n",
      "\n",
      "Epoch 21/30\n",
      " - 18s - loss: 0.7726\n",
      "\n",
      "Epoch 22/30\n",
      " - 18s - loss: 0.7294\n",
      "\n",
      "Epoch 23/30\n",
      " - 18s - loss: 0.6889\n",
      "\n",
      "Epoch 24/30\n",
      " - 18s - loss: 0.6521\n",
      "\n",
      "Epoch 25/30\n",
      " - 18s - loss: 0.6178\n",
      "\n",
      "Epoch 26/30\n",
      " - 18s - loss: 0.5921\n",
      "\n",
      "Epoch 27/30\n",
      " - 18s - loss: 0.5892\n",
      "\n",
      "Epoch 28/30\n",
      " - 18s - loss: 0.5893\n",
      "\n",
      "Epoch 29/30\n",
      " - 18s - loss: 0.5888\n",
      "\n",
      "Epoch 30/30\n",
      " - 18s - loss: 0.5888\n",
      "\n",
      "Epoch 1/30\n",
      " - 34s - loss: 29.2885\n",
      "\n",
      "Epoch 2/30\n",
      " - 28s - loss: 1.5430\n",
      "\n",
      "Epoch 3/30\n",
      " - 28s - loss: 0.9400\n",
      "\n",
      "Epoch 4/30\n",
      " - 28s - loss: 0.8380\n",
      "\n",
      "Epoch 5/30\n",
      " - 28s - loss: 0.7507\n",
      "\n",
      "Epoch 6/30\n",
      " - 29s - loss: 0.6712\n",
      "\n",
      "Epoch 7/30\n",
      " - 28s - loss: 0.5986\n",
      "\n",
      "Epoch 8/30\n",
      " - 28s - loss: 0.5328\n",
      "\n",
      "Epoch 9/30\n",
      " - 28s - loss: 0.4732\n",
      "\n",
      "Epoch 10/30\n",
      " - 28s - loss: 0.4194\n",
      "\n",
      "Epoch 11/30\n",
      " - 28s - loss: 0.3711\n",
      "\n",
      "Epoch 12/30\n",
      " - 28s - loss: 0.3280\n",
      "\n",
      "Epoch 13/30\n",
      " - 28s - loss: 0.2899\n",
      "\n",
      "Epoch 14/30\n",
      " - 28s - loss: 0.2561\n",
      "\n",
      "Epoch 15/30\n",
      " - 28s - loss: 0.2265\n",
      "\n",
      "Epoch 16/30\n",
      " - 28s - loss: 0.2008\n",
      "\n",
      "Epoch 17/30\n",
      " - 29s - loss: 0.1908\n",
      "\n",
      "Epoch 18/30\n",
      " - 28s - loss: 0.1906\n",
      "\n",
      "Epoch 19/30\n",
      " - 28s - loss: 0.1905\n",
      "\n",
      "Epoch 20/30\n",
      " - 28s - loss: 0.1901\n",
      "\n",
      "Epoch 21/30\n",
      " - 28s - loss: 0.1899\n",
      "\n",
      "Epoch 22/30\n",
      " - 28s - loss: 0.1896\n",
      "\n",
      "Epoch 23/30\n",
      " - 28s - loss: 0.1893\n",
      "\n",
      "Epoch 24/30\n",
      " - 28s - loss: 0.1892\n",
      "\n",
      "Epoch 25/30\n",
      " - 28s - loss: 0.1892\n",
      "\n",
      "Epoch 26/30\n",
      " - 28s - loss: 0.1894\n",
      "\n",
      "Epoch 27/30\n",
      " - 29s - loss: 0.1895\n",
      "\n",
      "Epoch 28/30\n",
      " - 28s - loss: 0.1897\n",
      "\n",
      "Epoch 29/30\n",
      " - 28s - loss: 0.1900\n",
      "\n",
      "Epoch 30/30\n",
      " - 28s - loss: 0.1903\n",
      "\n",
      "Epoch 1/30\n",
      " - 33s - loss: 53.0288\n",
      "\n",
      "Epoch 2/30\n",
      " - 26s - loss: 3.1132\n",
      "\n",
      "Epoch 3/30\n",
      " - 26s - loss: 2.4617\n",
      "\n",
      "Epoch 4/30\n",
      " - 26s - loss: 2.2526\n",
      "\n",
      "Epoch 5/30\n",
      " - 26s - loss: 2.0682\n",
      "\n",
      "Epoch 6/30\n",
      " - 26s - loss: 1.8988\n",
      "\n",
      "Epoch 7/30\n",
      " - 26s - loss: 1.7419\n",
      "\n",
      "Epoch 8/30\n",
      " - 26s - loss: 1.5978\n",
      "\n",
      "Epoch 9/30\n",
      " - 26s - loss: 1.4689\n",
      "\n",
      "Epoch 10/30\n",
      " - 26s - loss: 1.3543\n",
      "\n",
      "Epoch 11/30\n",
      " - 26s - loss: 1.2494\n",
      "\n",
      "Epoch 12/30\n",
      " - 26s - loss: 1.1520\n",
      "\n",
      "Epoch 13/30\n",
      " - 26s - loss: 1.0639\n",
      "\n",
      "Epoch 14/30\n",
      " - 26s - loss: 0.9863\n",
      "\n",
      "Epoch 15/30\n",
      " - 26s - loss: 0.9189\n",
      "\n",
      "Epoch 16/30\n",
      " - 26s - loss: 0.8602\n",
      "\n",
      "Epoch 17/30\n",
      " - 26s - loss: 0.8093\n",
      "\n",
      "Epoch 18/30\n",
      " - 26s - loss: 0.7711\n",
      "\n",
      "Epoch 19/30\n",
      " - 26s - loss: 0.7662\n",
      "\n",
      "Epoch 20/30\n",
      " - 26s - loss: 0.7666\n",
      "\n",
      "Epoch 21/30\n",
      " - 26s - loss: 0.7665\n",
      "\n",
      "Epoch 22/30\n",
      " - 26s - loss: 0.7664\n",
      "\n",
      "Epoch 23/30\n",
      " - 26s - loss: 0.7664\n",
      "\n",
      "Epoch 24/30\n",
      " - 26s - loss: 0.7662\n",
      "\n",
      "Epoch 25/30\n",
      " - 26s - loss: 0.7664\n",
      "\n",
      "Epoch 26/30\n",
      " - 26s - loss: 0.7665\n",
      "\n",
      "Epoch 27/30\n",
      " - 25s - loss: 0.7670\n",
      "\n",
      "Epoch 28/30\n",
      " - 25s - loss: 0.7678\n",
      "\n",
      "Epoch 29/30\n",
      " - 26s - loss: 0.7687\n",
      "\n",
      "Epoch 30/30\n",
      " - 25s - loss: 0.7694\n",
      "\n",
      "Epoch 1/30\n",
      " - 66s - loss: 28.0039\n",
      "\n",
      "Epoch 2/30\n",
      " - 60s - loss: 3.0248\n",
      "\n",
      "Epoch 3/30\n",
      " - 57s - loss: 2.4896\n",
      "\n",
      "Epoch 4/30\n",
      " - 57s - loss: 2.0475\n",
      "\n",
      "Epoch 5/30\n",
      " - 57s - loss: 1.6887\n",
      "\n",
      "Epoch 6/30\n",
      " - 58s - loss: 1.4009\n",
      "\n",
      "Epoch 7/30\n",
      " - 58s - loss: 1.1742\n",
      "\n",
      "Epoch 8/30\n",
      " - 57s - loss: 1.0094\n",
      "\n",
      "Epoch 9/30\n",
      " - 57s - loss: 0.9749\n",
      "\n",
      "Epoch 10/30\n",
      " - 58s - loss: 0.9780\n",
      "\n",
      "Epoch 11/30\n",
      " - 58s - loss: 0.9800\n",
      "\n",
      "Epoch 12/30\n",
      " - 57s - loss: 0.9810\n",
      "\n",
      "Epoch 13/30\n",
      " - 57s - loss: 0.9841\n",
      "\n",
      "Epoch 14/30\n",
      " - 57s - loss: 0.9879\n",
      "\n",
      "Epoch 15/30\n",
      " - 57s - loss: 0.9914\n",
      "\n",
      "Epoch 16/30\n",
      " - 58s - loss: 0.9952\n",
      "\n",
      "Epoch 17/30\n",
      " - 58s - loss: 1.0010\n",
      "\n",
      "Epoch 18/30\n",
      " - 57s - loss: 1.0056\n",
      "\n",
      "Epoch 19/30\n",
      " - 57s - loss: 1.0090\n",
      "\n",
      "Epoch 20/30\n",
      " - 57s - loss: 1.0101\n",
      "\n",
      "Epoch 21/30\n",
      " - 57s - loss: 1.0108\n",
      "\n",
      "Epoch 22/30\n",
      " - 58s - loss: 1.0110\n",
      "\n",
      "Epoch 23/30\n",
      " - 57s - loss: 1.0111\n",
      "\n",
      "Epoch 24/30\n",
      " - 57s - loss: 1.0114\n",
      "\n",
      "Epoch 25/30\n",
      " - 57s - loss: 1.0116\n",
      "\n",
      "Epoch 26/30\n",
      " - 58s - loss: 1.0118\n",
      "\n",
      "Epoch 27/30\n",
      " - 58s - loss: 1.0119\n",
      "\n",
      "Epoch 28/30\n",
      " - 57s - loss: 1.0122\n",
      "\n",
      "Epoch 29/30\n",
      " - 57s - loss: 1.0125\n",
      "\n",
      "Epoch 30/30\n",
      " - 57s - loss: 1.0124\n",
      "\n",
      "Epoch 1/30\n",
      " - 74s - loss: 51.9148\n",
      "\n",
      "Epoch 2/30\n",
      " - 66s - loss: 4.2944\n",
      "\n",
      "Epoch 3/30\n",
      " - 65s - loss: 3.7269\n",
      "\n",
      "Epoch 4/30\n",
      " - 65s - loss: 3.2712\n",
      "\n",
      "Epoch 5/30\n",
      " - 65s - loss: 2.9110\n",
      "\n",
      "Epoch 6/30\n",
      " - 66s - loss: 2.6337\n",
      "\n",
      "Epoch 7/30\n",
      " - 65s - loss: 2.4295\n",
      "\n",
      "Epoch 8/30\n",
      " - 65s - loss: 2.3650\n",
      "\n",
      "Epoch 9/30\n",
      " - 65s - loss: 2.3606\n",
      "\n",
      "Epoch 10/30\n",
      " - 65s - loss: 2.3585\n",
      "\n",
      "Epoch 11/30\n",
      " - 66s - loss: 2.3561\n",
      "\n",
      "Epoch 12/30\n",
      " - 65s - loss: 2.3552\n",
      "\n",
      "Epoch 13/30\n",
      " - 65s - loss: 2.3536\n",
      "\n",
      "Epoch 14/30\n",
      " - 65s - loss: 2.3505\n",
      "\n",
      "Epoch 15/30\n",
      " - 65s - loss: 2.3478\n",
      "\n",
      "Epoch 16/30\n",
      " - 66s - loss: 2.3437\n",
      "\n",
      "Epoch 17/30\n",
      " - 65s - loss: 2.3405\n",
      "\n",
      "Epoch 18/30\n",
      " - 65s - loss: 2.3363\n",
      "\n",
      "Epoch 19/30\n",
      " - 65s - loss: 2.3337\n",
      "\n",
      "Epoch 20/30\n",
      " - 66s - loss: 2.3309\n",
      "\n",
      "Epoch 21/30\n",
      " - 65s - loss: 2.3271\n",
      "\n",
      "Epoch 22/30\n",
      " - 65s - loss: 2.3248\n",
      "\n",
      "Epoch 23/30\n",
      " - 65s - loss: 2.3221\n",
      "\n",
      "Epoch 24/30\n",
      " - 65s - loss: 2.3207\n",
      "\n",
      "Epoch 25/30\n",
      " - 65s - loss: 2.3185\n",
      "\n",
      "Epoch 26/30\n",
      " - 65s - loss: 2.3182\n",
      "\n",
      "Epoch 27/30\n",
      " - 65s - loss: 2.3167\n",
      "\n",
      "Epoch 28/30\n",
      " - 65s - loss: 2.3152\n",
      "\n",
      "Epoch 29/30\n",
      " - 65s - loss: 2.3144\n",
      "\n",
      "Epoch 30/30\n",
      " - 65s - loss: 2.3114\n",
      "\n",
      "Epoch 1/30\n",
      " - 35s - loss: 80.9481\n",
      "\n",
      "Epoch 2/30\n",
      " - 26s - loss: 4.4614\n",
      "\n",
      "Epoch 3/30\n",
      " - 26s - loss: 3.8341\n",
      "\n",
      "Epoch 4/30\n",
      " - 25s - loss: 3.5591\n",
      "\n",
      "Epoch 5/30\n",
      " - 26s - loss: 3.3038\n",
      "\n",
      "Epoch 6/30\n",
      " - 26s - loss: 3.0704\n",
      "\n",
      "Epoch 7/30\n",
      " - 25s - loss: 2.8568\n",
      "\n",
      "Epoch 8/30\n",
      " - 25s - loss: 2.6590\n",
      "\n",
      "Epoch 9/30\n",
      " - 26s - loss: 2.4769\n",
      "\n",
      "Epoch 10/30\n",
      " - 25s - loss: 2.3141\n",
      "\n",
      "Epoch 11/30\n",
      " - 26s - loss: 2.1695\n",
      "\n",
      "Epoch 12/30\n",
      " - 26s - loss: 2.0433\n",
      "\n",
      "Epoch 13/30\n",
      " - 25s - loss: 1.9299\n",
      "\n",
      "Epoch 14/30\n",
      " - 25s - loss: 1.8255\n",
      "\n",
      "Epoch 15/30\n",
      " - 26s - loss: 1.7309\n",
      "\n",
      "Epoch 16/30\n",
      " - 26s - loss: 1.6475\n",
      "\n",
      "Epoch 17/30\n",
      " - 25s - loss: 1.5750\n",
      "\n",
      "Epoch 18/30\n",
      " - 25s - loss: 1.5226\n",
      "\n",
      "Epoch 19/30\n",
      " - 26s - loss: 1.5193\n",
      "\n",
      "Epoch 20/30\n",
      " - 26s - loss: 1.5270\n",
      "\n",
      "Epoch 21/30\n",
      " - 26s - loss: 1.5349\n",
      "\n",
      "Epoch 22/30\n",
      " - 26s - loss: 1.5415\n",
      "\n",
      "Epoch 23/30\n",
      " - 25s - loss: 1.5454\n",
      "\n",
      "Epoch 24/30\n",
      " - 26s - loss: 1.5474\n",
      "\n",
      "Epoch 25/30\n",
      " - 26s - loss: 1.5491\n",
      "\n",
      "Epoch 26/30\n",
      " - 25s - loss: 1.5490\n",
      "\n",
      "Epoch 27/30\n",
      " - 25s - loss: 1.5497\n",
      "\n",
      "Epoch 28/30\n",
      " - 26s - loss: 1.5511\n",
      "\n",
      "Epoch 29/30\n",
      " - 25s - loss: 1.5527\n",
      "\n",
      "Epoch 30/30\n",
      " - 26s - loss: 1.5539\n",
      "\n",
      "Epoch 1/30\n",
      " - 37s - loss: 75.9054\n",
      "\n",
      "Epoch 2/30\n",
      " - 27s - loss: 4.3120\n",
      "\n",
      "Epoch 3/30\n",
      " - 26s - loss: 3.6451\n",
      "\n",
      "Epoch 4/30\n",
      " - 26s - loss: 3.3671\n",
      "\n",
      "Epoch 5/30\n",
      " - 26s - loss: 3.1226\n",
      "\n",
      "Epoch 6/30\n",
      " - 26s - loss: 2.8998\n",
      "\n",
      "Epoch 7/30\n",
      " - 26s - loss: 2.6955\n",
      "\n",
      "Epoch 8/30\n",
      " - 26s - loss: 2.5077\n",
      "\n",
      "Epoch 9/30\n",
      " - 26s - loss: 2.3366\n",
      "\n",
      "Epoch 10/30\n",
      " - 26s - loss: 2.1817\n",
      "\n",
      "Epoch 11/30\n",
      " - 26s - loss: 2.0395\n",
      "\n",
      "Epoch 12/30\n",
      " - 26s - loss: 1.9104\n",
      "\n",
      "Epoch 13/30\n",
      " - 26s - loss: 1.7958\n",
      "\n",
      "Epoch 14/30\n",
      " - 26s - loss: 1.6930\n",
      "\n",
      "Epoch 15/30\n",
      " - 26s - loss: 1.6019\n",
      "\n",
      "Epoch 16/30\n",
      " - 26s - loss: 1.5203\n",
      "\n",
      "Epoch 17/30\n",
      " - 26s - loss: 1.4487\n",
      "\n",
      "Epoch 18/30\n",
      " - 26s - loss: 1.4028\n",
      "\n",
      "Epoch 19/30\n",
      " - 26s - loss: 1.3994\n",
      "\n",
      "Epoch 20/30\n",
      " - 26s - loss: 1.3980\n",
      "\n",
      "Epoch 21/30\n",
      " - 26s - loss: 1.3973\n",
      "\n",
      "Epoch 22/30\n",
      " - 26s - loss: 1.3968\n",
      "\n",
      "Epoch 23/30\n",
      " - 26s - loss: 1.3963\n",
      "\n",
      "Epoch 24/30\n",
      " - 26s - loss: 1.3966\n",
      "\n",
      "Epoch 25/30\n",
      " - 26s - loss: 1.3951\n",
      "\n",
      "Epoch 26/30\n",
      " - 26s - loss: 1.3956\n",
      "\n",
      "Epoch 27/30\n",
      " - 26s - loss: 1.3961\n",
      "\n",
      "Epoch 28/30\n",
      " - 26s - loss: 1.3968\n",
      "\n",
      "Epoch 29/30\n",
      " - 26s - loss: 1.3970\n",
      "\n",
      "Epoch 30/30\n",
      " - 26s - loss: 1.3980\n",
      "\n",
      "Epoch 1/30\n",
      " - 29s - loss: 119.3929\n",
      "\n",
      "Epoch 2/30\n",
      " - 17s - loss: 7.7943\n",
      "\n",
      "Epoch 3/30\n",
      " - 17s - loss: 3.7183\n",
      "\n",
      "Epoch 4/30\n",
      " - 17s - loss: 3.4601\n",
      "\n",
      "Epoch 5/30\n",
      " - 17s - loss: 3.2985\n",
      "\n",
      "Epoch 6/30\n",
      " - 17s - loss: 3.1438\n",
      "\n",
      "Epoch 7/30\n",
      " - 17s - loss: 3.0014\n",
      "\n",
      "Epoch 8/30\n",
      " - 17s - loss: 2.8641\n",
      "\n",
      "Epoch 9/30\n",
      " - 17s - loss: 2.7309\n",
      "\n",
      "Epoch 10/30\n",
      " - 17s - loss: 2.6098\n",
      "\n",
      "Epoch 11/30\n",
      " - 17s - loss: 2.4937\n",
      "\n",
      "Epoch 12/30\n",
      " - 17s - loss: 2.3807\n",
      "\n",
      "Epoch 13/30\n",
      " - 17s - loss: 2.2787\n",
      "\n",
      "Epoch 14/30\n",
      " - 17s - loss: 2.1807\n",
      "\n",
      "Epoch 15/30\n",
      " - 17s - loss: 2.0875\n",
      "\n",
      "Epoch 16/30\n",
      " - 17s - loss: 2.0008\n",
      "\n",
      "Epoch 17/30\n",
      " - 17s - loss: 1.9187\n",
      "\n",
      "Epoch 18/30\n",
      " - 17s - loss: 1.8415\n",
      "\n",
      "Epoch 19/30\n",
      " - 17s - loss: 1.7690\n",
      "\n",
      "Epoch 20/30\n",
      " - 17s - loss: 1.7038\n",
      "\n",
      "Epoch 21/30\n",
      " - 17s - loss: 1.6405\n",
      "\n",
      "Epoch 22/30\n",
      " - 17s - loss: 1.5821\n",
      "\n",
      "Epoch 23/30\n",
      " - 17s - loss: 1.5292\n",
      "\n",
      "Epoch 24/30\n",
      " - 17s - loss: 1.4783\n",
      "\n",
      "Epoch 25/30\n",
      " - 17s - loss: 1.4327\n",
      "\n",
      "Epoch 26/30\n",
      " - 17s - loss: 1.3908\n",
      "\n",
      "Epoch 27/30\n",
      " - 17s - loss: 1.3518\n",
      "\n",
      "Epoch 28/30\n",
      " - 17s - loss: 1.3308\n",
      "\n",
      "Epoch 29/30\n",
      " - 17s - loss: 1.3301\n",
      "\n",
      "Epoch 30/30\n",
      " - 17s - loss: 1.3294\n",
      "\n",
      "Epoch 1/30\n",
      " - 30s - loss: 74.1221\n",
      "\n",
      "Epoch 2/30\n",
      " - 18s - loss: 5.2321\n",
      "\n",
      "Epoch 3/30\n",
      " - 18s - loss: 2.8073\n",
      "\n",
      "Epoch 4/30\n",
      " - 18s - loss: 2.5823\n",
      "\n",
      "Epoch 5/30\n",
      " - 18s - loss: 2.4337\n",
      "\n",
      "Epoch 6/30\n",
      " - 18s - loss: 2.2949\n",
      "\n",
      "Epoch 7/30\n",
      " - 18s - loss: 2.1640\n",
      "\n",
      "Epoch 8/30\n",
      " - 18s - loss: 2.0399\n",
      "\n",
      "Epoch 9/30\n",
      " - 18s - loss: 1.9233\n",
      "\n",
      "Epoch 10/30\n",
      " - 18s - loss: 1.8126\n",
      "\n",
      "Epoch 11/30\n",
      " - 18s - loss: 1.7094\n",
      "\n",
      "Epoch 12/30\n",
      " - 18s - loss: 1.6121\n",
      "\n",
      "Epoch 13/30\n",
      " - 18s - loss: 1.5210\n",
      "\n",
      "Epoch 14/30\n",
      " - 18s - loss: 1.4353\n",
      "\n",
      "Epoch 15/30\n",
      " - 18s - loss: 1.3555\n",
      "\n",
      "Epoch 16/30\n",
      " - 18s - loss: 1.2803\n",
      "\n",
      "Epoch 17/30\n",
      " - 18s - loss: 1.2097\n",
      "\n",
      "Epoch 18/30\n",
      " - 18s - loss: 1.1453\n",
      "\n",
      "Epoch 19/30\n",
      " - 18s - loss: 1.0851\n",
      "\n",
      "Epoch 20/30\n",
      " - 18s - loss: 1.0291\n",
      "\n",
      "Epoch 21/30\n",
      " - 18s - loss: 0.9776\n",
      "\n",
      "Epoch 22/30\n",
      " - 18s - loss: 0.9304\n",
      "\n",
      "Epoch 23/30\n",
      " - 18s - loss: 0.8869\n",
      "\n",
      "Epoch 24/30\n",
      " - 18s - loss: 0.8469\n",
      "\n",
      "Epoch 25/30\n",
      " - 18s - loss: 0.8105\n",
      "\n",
      "Epoch 26/30\n",
      " - 18s - loss: 0.7931\n",
      "\n",
      "Epoch 27/30\n",
      " - 18s - loss: 0.7921\n",
      "\n",
      "Epoch 28/30\n",
      " - 18s - loss: 0.7911\n",
      "\n",
      "Epoch 29/30\n",
      " - 18s - loss: 0.7910\n",
      "\n",
      "Epoch 30/30\n",
      " - 18s - loss: 0.7898\n",
      "\n",
      "Epoch 1/30\n",
      " - 33s - loss: 34.6974\n",
      "\n",
      "Epoch 2/30\n",
      " - 20s - loss: 3.1697\n",
      "\n",
      "Epoch 3/30\n",
      " - 20s - loss: 1.6479\n",
      "\n",
      "Epoch 4/30\n",
      " - 20s - loss: 1.4971\n",
      "\n",
      "Epoch 5/30\n",
      " - 20s - loss: 1.3848\n",
      "\n",
      "Epoch 6/30\n",
      " - 20s - loss: 1.2803\n",
      "\n",
      "Epoch 7/30\n",
      " - 20s - loss: 1.1819\n",
      "\n",
      "Epoch 8/30\n",
      " - 20s - loss: 1.0895\n",
      "\n",
      "Epoch 9/30\n",
      " - 20s - loss: 1.0033\n",
      "\n",
      "Epoch 10/30\n",
      " - 20s - loss: 0.9224\n",
      "\n",
      "Epoch 11/30\n",
      " - 20s - loss: 0.8468\n",
      "\n",
      "Epoch 12/30\n",
      " - 20s - loss: 0.7765\n",
      "\n",
      "Epoch 13/30\n",
      " - 20s - loss: 0.7111\n",
      "\n",
      "Epoch 14/30\n",
      " - 20s - loss: 0.6500\n",
      "\n",
      "Epoch 15/30\n",
      " - 20s - loss: 0.5936\n",
      "\n",
      "Epoch 16/30\n",
      " - 20s - loss: 0.5413\n",
      "\n",
      "Epoch 17/30\n",
      " - 20s - loss: 0.4931\n",
      "\n",
      "Epoch 18/30\n",
      " - 20s - loss: 0.4490\n",
      "\n",
      "Epoch 19/30\n",
      " - 20s - loss: 0.4085\n",
      "\n",
      "Epoch 20/30\n",
      " - 20s - loss: 0.3714\n",
      "\n",
      "Epoch 21/30\n",
      " - 20s - loss: 0.3378\n",
      "\n",
      "Epoch 22/30\n",
      " - 20s - loss: 0.3072\n",
      "\n",
      "Epoch 23/30\n",
      " - 20s - loss: 0.2806\n",
      "\n",
      "Epoch 24/30\n",
      " - 20s - loss: 0.2739\n",
      "\n",
      "Epoch 25/30\n",
      " - 20s - loss: 0.2739\n",
      "\n",
      "Epoch 26/30\n",
      " - 20s - loss: 0.2736\n",
      "\n",
      "Epoch 27/30\n",
      " - 20s - loss: 0.2734\n",
      "\n",
      "Epoch 28/30\n",
      " - 20s - loss: 0.2732\n",
      "\n",
      "Epoch 29/30\n",
      " - 20s - loss: 0.2729\n",
      "\n",
      "Epoch 30/30\n",
      " - 20s - loss: 0.2727\n",
      "\n",
      "Epoch 1/30\n",
      " - 56s - loss: 27.8926\n",
      "\n",
      "Epoch 2/30\n",
      " - 41s - loss: 2.4164\n",
      "\n",
      "Epoch 3/30\n",
      " - 41s - loss: 2.0753\n",
      "\n",
      "Epoch 4/30\n",
      " - 41s - loss: 1.7846\n",
      "\n",
      "Epoch 5/30\n",
      " - 41s - loss: 1.5386\n",
      "\n",
      "Epoch 6/30\n",
      " - 41s - loss: 1.3246\n",
      "\n",
      "Epoch 7/30\n",
      " - 42s - loss: 1.1431\n",
      "\n",
      "Epoch 8/30\n",
      " - 41s - loss: 0.9896\n",
      "\n",
      "Epoch 9/30\n",
      " - 41s - loss: 0.8590\n",
      "\n",
      "Epoch 10/30\n",
      " - 41s - loss: 0.7502\n",
      "\n",
      "Epoch 11/30\n",
      " - 41s - loss: 0.6644\n",
      "\n",
      "Epoch 12/30\n",
      " - 41s - loss: 0.6442\n",
      "\n",
      "Epoch 13/30\n",
      " - 41s - loss: 0.6441\n",
      "\n",
      "Epoch 14/30\n",
      " - 42s - loss: 0.6444\n",
      "\n",
      "Epoch 15/30\n",
      " - 41s - loss: 0.6448\n",
      "\n",
      "Epoch 16/30\n",
      " - 41s - loss: 0.6453\n",
      "\n",
      "Epoch 17/30\n",
      " - 41s - loss: 0.6465\n",
      "\n",
      "Epoch 18/30\n",
      " - 41s - loss: 0.6479\n",
      "\n",
      "Epoch 19/30\n",
      " - 41s - loss: 0.6494\n",
      "\n",
      "Epoch 20/30\n",
      " - 41s - loss: 0.6504\n",
      "\n",
      "Epoch 21/30\n",
      " - 42s - loss: 0.6509\n",
      "\n",
      "Epoch 22/30\n",
      " - 41s - loss: 0.6512\n",
      "\n",
      "Epoch 23/30\n",
      " - 41s - loss: 0.6511\n",
      "\n",
      "Epoch 24/30\n",
      " - 41s - loss: 0.6513\n",
      "\n",
      "Epoch 25/30\n",
      " - 42s - loss: 0.6514\n",
      "\n",
      "Epoch 26/30\n",
      " - 41s - loss: 0.6514\n",
      "\n",
      "Epoch 27/30\n",
      " - 41s - loss: 0.6515\n",
      "\n",
      "Epoch 28/30\n",
      " - 41s - loss: 0.6514\n",
      "\n",
      "Epoch 29/30\n",
      " - 42s - loss: 0.6516\n",
      "\n",
      "Epoch 30/30\n",
      " - 41s - loss: 0.6516\n",
      "\n",
      "Epoch 1/30\n",
      " - 70s - loss: 59.1731\n",
      "\n",
      "Epoch 2/30\n",
      " - 55s - loss: 3.6629\n",
      "\n",
      "Epoch 3/30\n",
      " - 55s - loss: 3.2108\n",
      "\n",
      "Epoch 4/30\n",
      " - 56s - loss: 2.8296\n",
      "\n",
      "Epoch 5/30\n",
      " - 55s - loss: 2.5181\n",
      "\n",
      "Epoch 6/30\n",
      " - 55s - loss: 2.2628\n",
      "\n",
      "Epoch 7/30\n",
      " - 55s - loss: 2.0534\n",
      "\n",
      "Epoch 8/30\n",
      " - 55s - loss: 1.8973\n",
      "\n",
      "Epoch 9/30\n",
      " - 55s - loss: 1.8194\n",
      "\n",
      "Epoch 10/30\n",
      " - 56s - loss: 1.8249\n",
      "\n",
      "Epoch 11/30\n",
      " - 55s - loss: 1.8276\n",
      "\n",
      "Epoch 12/30\n",
      " - 55s - loss: 1.8258\n",
      "\n",
      "Epoch 13/30\n",
      " - 55s - loss: 1.8279\n",
      "\n",
      "Epoch 14/30\n",
      " - 55s - loss: 1.8335\n",
      "\n",
      "Epoch 15/30\n",
      " - 56s - loss: 1.8421\n",
      "\n",
      "Epoch 16/30\n",
      " - 55s - loss: 1.8560\n",
      "\n",
      "Epoch 17/30\n",
      " - 55s - loss: 1.8690\n",
      "\n",
      "Epoch 18/30\n",
      " - 55s - loss: 1.8789\n",
      "\n",
      "Epoch 19/30\n",
      " - 55s - loss: 1.8820\n",
      "\n",
      "Epoch 20/30\n",
      " - 55s - loss: 1.8836\n",
      "\n",
      "Epoch 21/30\n",
      " - 56s - loss: 1.8838\n",
      "\n",
      "Epoch 22/30\n",
      " - 55s - loss: 1.8839\n",
      "\n",
      "Epoch 23/30\n",
      " - 55s - loss: 1.8841\n",
      "\n",
      "Epoch 24/30\n",
      " - 55s - loss: 1.8847\n",
      "\n",
      "Epoch 25/30\n",
      " - 55s - loss: 1.8850\n",
      "\n",
      "Epoch 26/30\n",
      " - 55s - loss: 1.8851\n",
      "\n",
      "Epoch 27/30\n",
      " - 55s - loss: 1.8859\n",
      "\n",
      "Epoch 28/30\n",
      " - 55s - loss: 1.8859\n",
      "\n",
      "Epoch 29/30\n",
      " - 55s - loss: 1.8856\n",
      "\n",
      "Epoch 30/30\n",
      " - 55s - loss: 1.8858\n",
      "\n",
      "Epoch 1/30\n",
      " - 35s - loss: 22.1790\n",
      "\n",
      "Epoch 2/30\n",
      " - 20s - loss: 2.8009\n",
      "\n",
      "Epoch 3/30\n",
      " - 19s - loss: 1.8481\n",
      "\n",
      "Epoch 4/30\n",
      " - 19s - loss: 1.6836\n",
      "\n",
      "Epoch 5/30\n",
      " - 19s - loss: 1.5510\n",
      "\n",
      "Epoch 6/30\n",
      " - 19s - loss: 1.4270\n",
      "\n",
      "Epoch 7/30\n",
      " - 19s - loss: 1.3104\n",
      "\n",
      "Epoch 8/30\n",
      " - 19s - loss: 1.2007\n",
      "\n",
      "Epoch 9/30\n",
      " - 19s - loss: 1.0977\n",
      "\n",
      "Epoch 10/30\n",
      " - 19s - loss: 1.0015\n",
      "\n",
      "Epoch 11/30\n",
      " - 19s - loss: 0.9116\n",
      "\n",
      "Epoch 12/30\n",
      " - 19s - loss: 0.8276\n",
      "\n",
      "Epoch 13/30\n",
      " - 19s - loss: 0.7493\n",
      "\n",
      "Epoch 14/30\n",
      " - 19s - loss: 0.6764\n",
      "\n",
      "Epoch 15/30\n",
      " - 19s - loss: 0.6085\n",
      "\n",
      "Epoch 16/30\n",
      " - 19s - loss: 0.5456\n",
      "\n",
      "Epoch 17/30\n",
      " - 19s - loss: 0.4875\n",
      "\n",
      "Epoch 18/30\n",
      " - 20s - loss: 0.4343\n",
      "\n",
      "Epoch 19/30\n",
      " - 19s - loss: 0.3853\n",
      "\n",
      "Epoch 20/30\n",
      " - 19s - loss: 0.3407\n",
      "\n",
      "Epoch 21/30\n",
      " - 19s - loss: 0.2997\n",
      "\n",
      "Epoch 22/30\n",
      " - 19s - loss: 0.2625\n",
      "\n",
      "Epoch 23/30\n",
      " - 19s - loss: 0.2285\n",
      "\n",
      "Epoch 24/30\n",
      " - 19s - loss: 0.2106\n",
      "\n",
      "Epoch 25/30\n",
      " - 19s - loss: 0.2101\n",
      "\n",
      "Epoch 26/30\n",
      " - 19s - loss: 0.2102\n",
      "\n",
      "Epoch 27/30\n",
      " - 19s - loss: 0.2102\n",
      "\n",
      "Epoch 28/30\n",
      " - 19s - loss: 0.2101\n",
      "\n",
      "Epoch 29/30\n",
      " - 19s - loss: 0.2101\n",
      "\n",
      "Epoch 30/30\n",
      " - 19s - loss: 0.2103\n",
      "\n",
      "Epoch 1/30\n",
      " - 76s - loss: 23.6381\n",
      "\n",
      "Epoch 2/30\n",
      " - 58s - loss: 2.7038\n",
      "\n",
      "Epoch 3/30\n",
      " - 58s - loss: 2.2125\n",
      "\n",
      "Epoch 4/30\n",
      " - 58s - loss: 1.8068\n",
      "\n",
      "Epoch 5/30\n",
      " - 58s - loss: 1.4774\n",
      "\n",
      "Epoch 6/30\n",
      " - 58s - loss: 1.2110\n",
      "\n",
      "Epoch 7/30\n",
      " - 58s - loss: 1.0030\n",
      "\n",
      "Epoch 8/30\n",
      " - 58s - loss: 0.8523\n",
      "\n",
      "Epoch 9/30\n",
      " - 58s - loss: 0.8182\n",
      "\n",
      "Epoch 10/30\n",
      " - 58s - loss: 0.8197\n",
      "\n",
      "Epoch 11/30\n",
      " - 58s - loss: 0.8198\n",
      "\n",
      "Epoch 12/30\n",
      " - 58s - loss: 0.8214\n",
      "\n",
      "Epoch 13/30\n",
      " - 58s - loss: 0.8248\n",
      "\n",
      "Epoch 14/30\n",
      " - 58s - loss: 0.8295\n",
      "\n",
      "Epoch 15/30\n",
      " - 58s - loss: 0.8356\n",
      "\n",
      "Epoch 16/30\n",
      " - 58s - loss: 0.8408\n",
      "\n",
      "Epoch 17/30\n",
      " - 58s - loss: 0.8446\n",
      "\n",
      "Epoch 18/30\n",
      " - 58s - loss: 0.8458\n",
      "\n",
      "Epoch 19/30\n",
      " - 69s - loss: 0.8464\n",
      "\n",
      "Epoch 20/30\n",
      " - 58s - loss: 0.8466\n",
      "\n",
      "Epoch 21/30\n",
      " - 58s - loss: 0.8468\n",
      "\n",
      "Epoch 22/30\n",
      " - 58s - loss: 0.8469\n",
      "\n",
      "Epoch 23/30\n",
      " - 58s - loss: 0.8469\n",
      "\n",
      "Epoch 24/30\n",
      " - 58s - loss: 0.8471\n",
      "\n",
      "Epoch 25/30\n",
      " - 58s - loss: 0.8472\n",
      "\n",
      "Epoch 26/30\n",
      " - 58s - loss: 0.8474\n",
      "\n",
      "Epoch 27/30\n",
      " - 58s - loss: 0.8474\n",
      "\n",
      "Epoch 28/30\n",
      " - 58s - loss: 0.8474\n",
      "\n",
      "Epoch 29/30\n",
      " - 59s - loss: 0.8475\n",
      "\n",
      "Epoch 30/30\n",
      " - 58s - loss: 0.8475\n",
      "\n",
      "Epoch 1/30\n",
      " - 41s - loss: 74.5896\n",
      "\n",
      "Epoch 2/30\n",
      " - 23s - loss: 3.7200\n",
      "\n",
      "Epoch 3/30\n",
      " - 24s - loss: 1.4805\n",
      "\n",
      "Epoch 4/30\n",
      " - 23s - loss: 1.3631\n",
      "\n",
      "Epoch 5/30\n",
      " - 23s - loss: 1.2684\n",
      "\n",
      "Epoch 6/30\n",
      " - 23s - loss: 1.1799\n",
      "\n",
      "Epoch 7/30\n",
      " - 23s - loss: 1.0976\n",
      "\n",
      "Epoch 8/30\n",
      " - 23s - loss: 1.0224\n",
      "\n",
      "Epoch 9/30\n",
      " - 23s - loss: 0.9515\n",
      "\n",
      "Epoch 10/30\n",
      " - 23s - loss: 0.8868\n",
      "\n",
      "Epoch 11/30\n",
      " - 23s - loss: 0.8277\n",
      "\n",
      "Epoch 12/30\n",
      " - 23s - loss: 0.7727\n",
      "\n",
      "Epoch 13/30\n",
      " - 23s - loss: 0.7218\n",
      "\n",
      "Epoch 14/30\n",
      " - 23s - loss: 0.6751\n",
      "\n",
      "Epoch 15/30\n",
      " - 23s - loss: 0.6335\n",
      "\n",
      "Epoch 16/30\n",
      " - 24s - loss: 0.5964\n",
      "\n",
      "Epoch 17/30\n",
      " - 23s - loss: 0.5635\n",
      "\n",
      "Epoch 18/30\n",
      " - 23s - loss: 0.5345\n",
      "\n",
      "Epoch 19/30\n",
      " - 23s - loss: 0.5091\n",
      "\n",
      "Epoch 20/30\n",
      " - 23s - loss: 0.4882\n",
      "\n",
      "Epoch 21/30\n",
      " - 23s - loss: 0.4851\n",
      "\n",
      "Epoch 22/30\n",
      " - 23s - loss: 0.4851\n",
      "\n",
      "Epoch 23/30\n",
      " - 23s - loss: 0.4848\n",
      "\n",
      "Epoch 24/30\n",
      " - 23s - loss: 0.4839\n",
      "\n",
      "Epoch 25/30\n",
      " - 23s - loss: 0.4833\n",
      "\n",
      "Epoch 26/30\n",
      " - 23s - loss: 0.4836\n",
      "\n",
      "Epoch 27/30\n",
      " - 23s - loss: 0.4835\n",
      "\n",
      "Epoch 28/30\n",
      " - 23s - loss: 0.4841\n",
      "\n",
      "Epoch 29/30\n",
      " - 24s - loss: 0.4847\n",
      "\n",
      "Epoch 30/30\n",
      " - 23s - loss: 0.4858\n",
      "\n",
      "Epoch 1/30\n",
      " - 49s - loss: 48.8330\n",
      "\n",
      "Epoch 2/30\n",
      " - 30s - loss: 3.3456\n",
      "\n",
      "Epoch 3/30\n",
      " - 30s - loss: 2.8791\n",
      "\n",
      "Epoch 4/30\n",
      " - 30s - loss: 2.6185\n",
      "\n",
      "Epoch 5/30\n",
      " - 30s - loss: 2.3837\n",
      "\n",
      "Epoch 6/30\n",
      " - 30s - loss: 2.1712\n",
      "\n",
      "Epoch 7/30\n",
      " - 30s - loss: 1.9786\n",
      "\n",
      "Epoch 8/30\n",
      " - 30s - loss: 1.8054\n",
      "\n",
      "Epoch 9/30\n",
      " - 30s - loss: 1.6492\n",
      "\n",
      "Epoch 10/30\n",
      " - 30s - loss: 1.5089\n",
      "\n",
      "Epoch 11/30\n",
      " - 30s - loss: 1.3844\n",
      "\n",
      "Epoch 12/30\n",
      " - 30s - loss: 1.2749\n",
      "\n",
      "Epoch 13/30\n",
      " - 30s - loss: 1.1790\n",
      "\n",
      "Epoch 14/30\n",
      " - 30s - loss: 1.0956\n",
      "\n",
      "Epoch 15/30\n",
      " - 30s - loss: 1.0233\n",
      "\n",
      "Epoch 16/30\n",
      " - 30s - loss: 0.9896\n",
      "\n",
      "Epoch 17/30\n",
      " - 30s - loss: 0.9872\n",
      "\n",
      "Epoch 18/30\n",
      " - 30s - loss: 0.9863\n",
      "\n",
      "Epoch 19/30\n",
      " - 31s - loss: 0.9855\n",
      "\n",
      "Epoch 20/30\n",
      " - 30s - loss: 0.9850\n",
      "\n",
      "Epoch 21/30\n",
      " - 30s - loss: 0.9848\n",
      "\n",
      "Epoch 22/30\n",
      " - 30s - loss: 0.9844\n",
      "\n",
      "Epoch 23/30\n",
      " - 30s - loss: 0.9841\n",
      "\n",
      "Epoch 24/30\n",
      " - 30s - loss: 0.9839\n",
      "\n",
      "Epoch 25/30\n",
      " - 30s - loss: 0.9841\n",
      "\n",
      "Epoch 26/30\n",
      " - 30s - loss: 0.9838\n",
      "\n",
      "Epoch 27/30\n",
      " - 30s - loss: 0.9832\n",
      "\n",
      "Epoch 28/30\n",
      " - 30s - loss: 0.9825\n",
      "\n",
      "Epoch 29/30\n",
      " - 31s - loss: 0.9820\n",
      "\n",
      "Epoch 30/30\n",
      " - 30s - loss: 0.9817\n",
      "\n",
      "Epoch 1/30\n",
      " - 78s - loss: 33.8512\n",
      "\n",
      "Epoch 2/30\n",
      " - 58s - loss: 2.6550\n",
      "\n",
      "Epoch 3/30\n",
      " - 58s - loss: 2.2145\n",
      "\n",
      "Epoch 4/30\n",
      " - 59s - loss: 1.8503\n",
      "\n",
      "Epoch 5/30\n",
      " - 58s - loss: 1.5557\n",
      "\n",
      "Epoch 6/30\n",
      " - 58s - loss: 1.3191\n",
      "\n",
      "Epoch 7/30\n",
      " - 58s - loss: 1.1324\n",
      "\n",
      "Epoch 8/30\n",
      " - 58s - loss: 0.9984\n",
      "\n",
      "Epoch 9/30\n",
      " - 59s - loss: 0.9724\n",
      "\n",
      "Epoch 10/30\n",
      " - 58s - loss: 0.9757\n",
      "\n",
      "Epoch 11/30\n",
      " - 58s - loss: 0.9770\n",
      "\n",
      "Epoch 12/30\n",
      " - 58s - loss: 0.9769\n",
      "\n",
      "Epoch 13/30\n",
      " - 58s - loss: 0.9792\n",
      "\n",
      "Epoch 14/30\n",
      " - 58s - loss: 0.9830\n",
      "\n",
      "Epoch 15/30\n",
      " - 59s - loss: 0.9874\n",
      "\n",
      "Epoch 16/30\n",
      " - 58s - loss: 0.9939\n",
      "\n",
      "Epoch 17/30\n",
      " - 58s - loss: 0.9998\n",
      "\n",
      "Epoch 18/30\n",
      " - 58s - loss: 1.0043\n",
      "\n",
      "Epoch 19/30\n",
      " - 58s - loss: 1.0060\n",
      "\n",
      "Epoch 20/30\n",
      " - 59s - loss: 1.0067\n",
      "\n",
      "Epoch 21/30\n",
      " - 58s - loss: 1.0070\n",
      "\n",
      "Epoch 22/30\n",
      " - 58s - loss: 1.0071\n",
      "\n",
      "Epoch 23/30\n",
      " - 58s - loss: 1.0071\n",
      "\n",
      "Epoch 24/30\n",
      " - 58s - loss: 1.0073\n",
      "\n",
      "Epoch 25/30\n",
      " - 59s - loss: 1.0074\n",
      "\n",
      "Epoch 26/30\n",
      " - 58s - loss: 1.0076\n",
      "\n",
      "Epoch 27/30\n",
      " - 58s - loss: 1.0077\n",
      "\n",
      "Epoch 28/30\n",
      " - 58s - loss: 1.0078\n",
      "\n",
      "Epoch 29/30\n",
      " - 58s - loss: 1.0079\n",
      "\n",
      "Epoch 30/30\n",
      " - 59s - loss: 1.0079\n",
      "\n",
      "Epoch 1/30\n",
      " - 39s - loss: 15.2697\n",
      "\n",
      "Epoch 2/30\n",
      " - 18s - loss: 3.2169\n",
      "\n",
      "Epoch 3/30\n",
      " - 18s - loss: 1.8764\n",
      "\n",
      "Epoch 4/30\n",
      " - 18s - loss: 1.6096\n",
      "\n",
      "Epoch 5/30\n",
      " - 18s - loss: 1.4573\n",
      "\n",
      "Epoch 6/30\n",
      " - 18s - loss: 1.3359\n",
      "\n",
      "Epoch 7/30\n",
      " - 18s - loss: 1.2289\n",
      "\n",
      "Epoch 8/30\n",
      " - 17s - loss: 1.1311\n",
      "\n",
      "Epoch 9/30\n",
      " - 18s - loss: 1.0403\n",
      "\n",
      "Epoch 10/30\n",
      " - 18s - loss: 0.9554\n",
      "\n",
      "Epoch 11/30\n",
      " - 18s - loss: 0.8757\n",
      "\n",
      "Epoch 12/30\n",
      " - 18s - loss: 0.8007\n",
      "\n",
      "Epoch 13/30\n",
      " - 18s - loss: 0.7304\n",
      "\n",
      "Epoch 14/30\n",
      " - 18s - loss: 0.6641\n",
      "\n",
      "Epoch 15/30\n",
      " - 18s - loss: 0.6020\n",
      "\n",
      "Epoch 16/30\n",
      " - 18s - loss: 0.5437\n",
      "\n",
      "Epoch 17/30\n",
      " - 18s - loss: 0.4890\n",
      "\n",
      "Epoch 18/30\n",
      " - 17s - loss: 0.4379\n",
      "\n",
      "Epoch 19/30\n",
      " - 17s - loss: 0.3904\n",
      "\n",
      "Epoch 20/30\n",
      " - 18s - loss: 0.3462\n",
      "\n",
      "Epoch 21/30\n",
      " - 18s - loss: 0.3052\n",
      "\n",
      "Epoch 22/30\n",
      " - 17s - loss: 0.2673\n",
      "\n",
      "Epoch 23/30\n",
      " - 18s - loss: 0.2323\n",
      "\n",
      "Epoch 24/30\n",
      " - 18s - loss: 0.2000\n",
      "\n",
      "Epoch 25/30\n",
      " - 17s - loss: 0.1703\n",
      "\n",
      "Epoch 26/30\n",
      " - 17s - loss: 0.1429\n",
      "\n",
      "Epoch 27/30\n",
      " - 17s - loss: 0.1294\n",
      "\n",
      "Epoch 28/30\n",
      " - 17s - loss: 0.1287\n",
      "\n",
      "Epoch 29/30\n",
      " - 18s - loss: 0.1288\n",
      "\n",
      "Epoch 30/30\n",
      " - 18s - loss: 0.1288\n",
      "\n",
      "Epoch 1/30\n",
      " - 50s - loss: 40.0728\n",
      "\n",
      "Epoch 2/30\n",
      " - 28s - loss: 1.7046\n",
      "\n",
      "Epoch 3/30\n",
      " - 28s - loss: 1.1994\n",
      "\n",
      "Epoch 4/30\n",
      " - 28s - loss: 1.0868\n",
      "\n",
      "Epoch 5/30\n",
      " - 28s - loss: 0.9843\n",
      "\n",
      "Epoch 6/30\n",
      " - 28s - loss: 0.8908\n",
      "\n",
      "Epoch 7/30\n",
      " - 28s - loss: 0.8055\n",
      "\n",
      "Epoch 8/30\n",
      " - 28s - loss: 0.7280\n",
      "\n",
      "Epoch 9/30\n",
      " - 28s - loss: 0.6583\n",
      "\n",
      "Epoch 10/30\n",
      " - 28s - loss: 0.5948\n",
      "\n",
      "Epoch 11/30\n",
      " - 28s - loss: 0.5373\n",
      "\n",
      "Epoch 12/30\n",
      " - 28s - loss: 0.4861\n",
      "\n",
      "Epoch 13/30\n",
      " - 28s - loss: 0.4412\n",
      "\n",
      "Epoch 14/30\n",
      " - 28s - loss: 0.4021\n",
      "\n",
      "Epoch 15/30\n",
      " - 28s - loss: 0.3684\n",
      "\n",
      "Epoch 16/30\n",
      " - 28s - loss: 0.3386\n",
      "\n",
      "Epoch 17/30\n",
      " - 28s - loss: 0.3223\n",
      "\n",
      "Epoch 18/30\n",
      " - 28s - loss: 0.3220\n",
      "\n",
      "Epoch 19/30\n",
      " - 28s - loss: 0.3216\n",
      "\n",
      "Epoch 20/30\n",
      " - 28s - loss: 0.3215\n",
      "\n",
      "Epoch 21/30\n",
      " - 28s - loss: 0.3216\n",
      "\n",
      "Epoch 22/30\n",
      " - 28s - loss: 0.3220\n",
      "\n",
      "Epoch 23/30\n",
      " - 28s - loss: 0.3224\n",
      "\n",
      "Epoch 24/30\n",
      " - 28s - loss: 0.3231\n",
      "\n",
      "Epoch 25/30\n",
      " - 28s - loss: 0.3241\n",
      "\n",
      "Epoch 26/30\n",
      " - 28s - loss: 0.3255\n",
      "\n",
      "Epoch 27/30\n",
      " - 28s - loss: 0.3271\n",
      "\n",
      "Epoch 28/30\n",
      " - 28s - loss: 0.3283\n",
      "\n",
      "Epoch 29/30\n",
      " - 28s - loss: 0.3296\n",
      "\n",
      "Epoch 30/30\n",
      " - 28s - loss: 0.3304\n",
      "\n",
      " 44%|████▍     | 20/45 [5:46:38<6:56:24, 999.39s/it, best loss: 1.8527601299120553] \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9ab5cd3efdb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0mfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"res.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         )\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    406\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    407\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                                           d['result'].get('status')))\n\u001b[1;32m    210\u001b[0m                         new_trials = algo(new_ids, self.domain, trials,\n\u001b[0;32m--> 211\u001b[0;31m                                           self.rstate.randint(2 ** 31 - 1))\n\u001b[0m\u001b[1;32m    212\u001b[0m                         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/tpe.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(new_ids, domain, trials, seed, prior_weight, n_startup_jobs, n_EI_candidates, gamma, linear_forgetting)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     idxs, vals = pyll.rec_eval([opt_idxs, opt_vals], memo=memo,\n\u001b[0;32m--> 900\u001b[0;31m                                print_node_on_error=False)\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;31m# -- retrieve the best of the samples and form the return tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/pyll/base.py\u001b[0m in \u001b[0;36mrec_eval\u001b[0;34m(expr, deepcopy_inputs, memo, max_program_len, memo_gc, print_trace, print_node_on_error)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m                 \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/hyperopt/tpe.py\u001b[0m in \u001b[0;36madaptive_parzen_normal\u001b[0;34m(mus, prior_weight, prior_mu, prior_sigma, LF)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0msigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprior_pos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior_sigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mprior_sigma\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmaxsigma\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mminsigma\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hyper-parameters optimisation for birdirectional(Long Short Term Memory)",
    "#!pip install keras-self-attention\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import keras\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "import  os\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from keras.regularizers import L1L2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import  pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "forword=15\n",
    "look_back=60\n",
    "tr_size=0.86\n",
    "\n",
    "\n",
    "df=pd.read_excel('test_data.xlsx')\n",
    "df1=df.copy()\n",
    "\n",
    "\n",
    "df1=df1[['日期（月度）','USA_output','OPEC_output','demand_current','supply_current']]\n",
    "#df1=df1.bfill()\n",
    "df1=df1.dropna()\n",
    "\n",
    "\n",
    "df1=df1.rename(columns={\"日期（月度）\":'日期（日期）'})\n",
    "df1=df1.set_index('日期（日期）')\n",
    "\n",
    "\n",
    "df1=df1.asfreq(freq='d')\n",
    "\n",
    "df1=df1.bfill()\n",
    "#print(df1.head(40))\n",
    "\n",
    "df=df.set_index('日期（日期）')\n",
    "\n",
    "\n",
    "df=df[['Brent','USD','CRB','Premium','trade','BDI']]\n",
    "\n",
    "\n",
    "df=df.ffill()\n",
    "df=df.bfill()\n",
    "\n",
    "\n",
    "\n",
    "df=df.join(df1)\n",
    "\n",
    "df=df.dropna()\n",
    "df=df.astype('float64')\n",
    "\n",
    "df_raw=df.copy()\n",
    "df = df.diff().dropna()\n",
    "\n",
    "print(df.shape[0])\n",
    "print(df_raw.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(df)\n",
    "\n",
    "\n",
    "\n",
    "#df=df.iloc[0:50]\n",
    "\n",
    "\n",
    "\n",
    "dataset=df.values\n",
    "#dataset = dataset.astype('float32')\n",
    "#print(dataset)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(len(dataset) * tr_size)\n",
    "trainlist = dataset[:train_size]\n",
    "testlist = dataset[train_size:]\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(dataset, look_back,forword):\n",
    "\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-forword):\n",
    "            a = dataset[i:(i+look_back)]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[(i + look_back):(i+look_back+forword)])\n",
    "        return np.array(dataX),np.array(dataY)\n",
    "\n",
    "\n",
    "trainX,trainY  = create_dataset(trainlist,look_back,forword)\n",
    "testX,testY = create_dataset(testlist,look_back,forword)\n",
    "\n",
    "\n",
    "trainY=np.reshape(trainY,(trainY.shape[0],-1))\n",
    "\n",
    "\n",
    "def retrive(hat):\n",
    "    hat=np.reshape(hat,(-1,df.shape[1]))\n",
    "    hat=scaler.inverse_transform(hat)\n",
    "    hat=np.reshape(hat,(-1,forword,df.shape[1]))\n",
    "    ind=train_size+look_back-1\n",
    "    result=[]\n",
    "    for y in range(hat.shape[0]):\n",
    "        ind_temp=ind+y\n",
    "        temp=np.array([ hat[y][x][0] for x in range(forword)])\n",
    "        las=df_raw.iloc[(ind_temp+1)]['Brent']\n",
    "        temp=np.insert(temp,0,las)\n",
    "        temp=np.cumsum(temp)\n",
    "        result.append(temp[1:])\n",
    "    #print(np.array(result))\n",
    "    return np.array(result)\n",
    "\n",
    "y_glob=retrive(testY)\n",
    "\n",
    "#print(trainX)\n",
    "#print(trainY)\n",
    "\n",
    "\n",
    "space= { \n",
    "                      'units3': hp.quniform('units3',64,512,1),\n",
    "                      'dropout3': hp.uniform('dropout3',0.25,0.75),\n",
    "    'rec3': hp.uniform('rec',0.25,0.75),\n",
    " \n",
    "                                        \n",
    "'batch_size' : hp.quniform('batch_size',28,128,1),\n",
    "'units1':hp.quniform('units1',64,512,1),\n",
    "\n",
    "'dropout1':hp.uniform('dropout1',0.25,0.75),\n",
    "    'rec1': hp.uniform('rec1',0.25,0.75),\n",
    "    'ker1_1': hp.uniform('ker1_1',0.01,0),\n",
    "    'ker1_2': hp.uniform('ker1_2',0.01,0),\n",
    "    'ker1_3': hp.uniform('ker1_3',0.01,0),\n",
    "    'ker1_4': hp.uniform('ker1_4',0.01,0),\n",
    "}\n",
    "\n",
    "\n",
    "def trainModel(params):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(int(params['units1']), dropout=params['dropout1'], recurrent_dropout=params['rec1'],kernel_regularizer=L1L2(l1=params['ker1_1'], l2=params['ker1_2']), recurrent_regularizer=L1L2(l1=0.001, l2=0.001), bias_regularizer=L1L2(l1=0.001, l2=0.001),return_sequences=True), input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Bidirectional(LSTM(int(params['units3']), dropout=params['dropout3'], recurrent_dropout=params['rec3'],kernel_regularizer=L1L2(l1=params['ker1_3'], l2=params['ker1_4']), recurrent_regularizer=L1L2(l1=0.001, l2=0.001), bias_regularizer=L1L2(l1=0.001, l2=0.001),return_sequences=True)))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid',kernel_regularizer=L1L2(l1=0.0001, l2=0.0001),bias_regularizer=L1L2(l1=0.0001, l2=0.0001),attention_regularizer_weight=1e-4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(trainY.shape[1]))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    model.fit(trainX, trainY, epochs=30, batch_size=int(params['batch_size']), verbose=2)\n",
    "    y_hat  =  model.predict(testX)\n",
    "\n",
    "\n",
    "\n",
    "    diff=retrive(y_hat)-y_glob\n",
    "\n",
    "    #rmse=np.sqrt((diff**2).mean())\n",
    "    mae=(np.abs(diff)).mean()\n",
    "    return {'loss': mae, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(trainModel, space, algo=tpe.suggest, max_evals=45, trials=trials)\n",
    "fo = open(\"res.txt\", \"w\")\n",
    "fo.write( repr(best))\n",
    "fo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
